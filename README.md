Reinforcement-Learning-for-Dynamic-Pricing-Uber-Surge-Pricing-Case-Study
● Applied Reinforcement Learning (Q-Learning) to simulate Uber’s surge pricing strategy, optimizing real-time price multipliers based on demand-supply dynamics, location, and events.
● Modeled an agent-environment feedback loop where the system learns to balance supply, demand, and wait times while maximizing long-term rewards.
● Evaluated RL performance against static pricing baselines, achieving higher average rewards, improved ride completions, and reduced unserved demand.
● Addressed ethical and managerial implications, emphasizing fairness, transparency, and scalability in data-driven pricing systems.
● Demonstrated potential extensions of RL to inventory management, logistics optimization, airline ticketing, and energy systems.
